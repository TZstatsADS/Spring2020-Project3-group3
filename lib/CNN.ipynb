{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv1D, MaxPooling1D, Dropout, Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature5998</th>\n",
       "      <th>feature5999</th>\n",
       "      <th>feature6000</th>\n",
       "      <th>feature6001</th>\n",
       "      <th>feature6002</th>\n",
       "      <th>feature6003</th>\n",
       "      <th>feature6004</th>\n",
       "      <th>feature6005</th>\n",
       "      <th>feature6006</th>\n",
       "      <th>emotion_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>36</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>148</td>\n",
       "      <td>114</td>\n",
       "      <td>...</td>\n",
       "      <td>96</td>\n",
       "      <td>146</td>\n",
       "      <td>196</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>143</td>\n",
       "      <td>114</td>\n",
       "      <td>...</td>\n",
       "      <td>94</td>\n",
       "      <td>151</td>\n",
       "      <td>203</td>\n",
       "      <td>49</td>\n",
       "      <td>106</td>\n",
       "      <td>158</td>\n",
       "      <td>57</td>\n",
       "      <td>109</td>\n",
       "      <td>52</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>135</td>\n",
       "      <td>106</td>\n",
       "      <td>...</td>\n",
       "      <td>97</td>\n",
       "      <td>144</td>\n",
       "      <td>184</td>\n",
       "      <td>46</td>\n",
       "      <td>93</td>\n",
       "      <td>133</td>\n",
       "      <td>47</td>\n",
       "      <td>87</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>141</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>155</td>\n",
       "      <td>208</td>\n",
       "      <td>53</td>\n",
       "      <td>105</td>\n",
       "      <td>158</td>\n",
       "      <td>52</td>\n",
       "      <td>105</td>\n",
       "      <td>53</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>164</td>\n",
       "      <td>122</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>158</td>\n",
       "      <td>212</td>\n",
       "      <td>54</td>\n",
       "      <td>109</td>\n",
       "      <td>163</td>\n",
       "      <td>55</td>\n",
       "      <td>109</td>\n",
       "      <td>54</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2495</td>\n",
       "      <td>40</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>140</td>\n",
       "      <td>106</td>\n",
       "      <td>...</td>\n",
       "      <td>95</td>\n",
       "      <td>145</td>\n",
       "      <td>194</td>\n",
       "      <td>49</td>\n",
       "      <td>99</td>\n",
       "      <td>148</td>\n",
       "      <td>50</td>\n",
       "      <td>99</td>\n",
       "      <td>49</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2496</td>\n",
       "      <td>38</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>36</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>160</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>109</td>\n",
       "      <td>162</td>\n",
       "      <td>208</td>\n",
       "      <td>53</td>\n",
       "      <td>106</td>\n",
       "      <td>152</td>\n",
       "      <td>53</td>\n",
       "      <td>99</td>\n",
       "      <td>46</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2497</td>\n",
       "      <td>33</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>40</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>149</td>\n",
       "      <td>108</td>\n",
       "      <td>...</td>\n",
       "      <td>90</td>\n",
       "      <td>138</td>\n",
       "      <td>188</td>\n",
       "      <td>46</td>\n",
       "      <td>94</td>\n",
       "      <td>144</td>\n",
       "      <td>48</td>\n",
       "      <td>98</td>\n",
       "      <td>50</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2498</td>\n",
       "      <td>35</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>36</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>153</td>\n",
       "      <td>114</td>\n",
       "      <td>...</td>\n",
       "      <td>93</td>\n",
       "      <td>144</td>\n",
       "      <td>197</td>\n",
       "      <td>49</td>\n",
       "      <td>100</td>\n",
       "      <td>153</td>\n",
       "      <td>51</td>\n",
       "      <td>104</td>\n",
       "      <td>53</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2499</td>\n",
       "      <td>38</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>173</td>\n",
       "      <td>131</td>\n",
       "      <td>...</td>\n",
       "      <td>93</td>\n",
       "      <td>141</td>\n",
       "      <td>192</td>\n",
       "      <td>44</td>\n",
       "      <td>92</td>\n",
       "      <td>143</td>\n",
       "      <td>48</td>\n",
       "      <td>99</td>\n",
       "      <td>51</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows Ã— 6007 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0           39        19         2        21        36        16         5   \n",
       "1           30        17         5        12        30        15         2   \n",
       "2           30        14         1        18        35        19         2   \n",
       "3           34        20         3        15        32        17         0   \n",
       "4           44        24         2        20        40        19         2   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2495        40        22         2        17        30        15         5   \n",
       "2496        38        19         3        13        36        20         2   \n",
       "2497        33        21         1        19        40        23         2   \n",
       "2498        35        18         3        20        36        19         0   \n",
       "2499        38        18         1        22        43        23         5   \n",
       "\n",
       "      feature8  feature9  feature10  ...  feature5998  feature5999  \\\n",
       "0           24       148        114  ...           96          146   \n",
       "1           11       143        114  ...           94          151   \n",
       "2           15       135        106  ...           97          144   \n",
       "3           17       141        109  ...          103          155   \n",
       "4           23       164        122  ...          103          158   \n",
       "...        ...       ...        ...  ...          ...          ...   \n",
       "2495        23       140        106  ...           95          145   \n",
       "2496        20       160        119  ...          109          162   \n",
       "2497        18       149        108  ...           90          138   \n",
       "2498        21       153        114  ...           93          144   \n",
       "2499        16       173        131  ...           93          141   \n",
       "\n",
       "      feature6000  feature6001  feature6002  feature6003  feature6004  \\\n",
       "0             196           50          100          150           50   \n",
       "1             203           49          106          158           57   \n",
       "2             184           46           93          133           47   \n",
       "3             208           53          105          158           52   \n",
       "4             212           54          109          163           55   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "2495          194           49           99          148           50   \n",
       "2496          208           53          106          152           53   \n",
       "2497          188           46           94          144           48   \n",
       "2498          197           49          100          153           51   \n",
       "2499          192           44           92          143           48   \n",
       "\n",
       "      feature6005  feature6006  emotion_idx  \n",
       "0             100           50           13  \n",
       "1             109           52            9  \n",
       "2              87           40            6  \n",
       "3             105           53           20  \n",
       "4             109           54            9  \n",
       "...           ...          ...          ...  \n",
       "2495           99           49           22  \n",
       "2496           99           46           22  \n",
       "2497           98           50           22  \n",
       "2498          104           53           22  \n",
       "2499           99           51           22  \n",
       "\n",
       "[2500 rows x 6007 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'C:/Users/59482/Desktop/Columbia/Second Term/ads/Project3/Spring2020-Project3-ads-spring2020-project3-group3/data/'\n",
    "dat_train = pd.read_csv(path+\"dat_train.csv\")\n",
    "dat_test=pd.read_csv(path+\"dat_test.csv\")\n",
    "dat_full=pd.read_csv(path+\"dat_full.csv\")\n",
    "dat_full.drop('Unnamed: 0', inplace=True, axis=1)\n",
    "dat_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.3859101 ,  0.42894874, -0.15423943, ..., -0.32021489,\n",
       "         1.0694245 ,  0.41341669],\n",
       "       [-0.64381387, -1.14091168, -0.15044509, ..., -1.61463967,\n",
       "        -2.71085251, -0.48615836],\n",
       "       [-1.60667719, -1.37835656,  0.79087003, ...,  1.25159942,\n",
       "        -1.81300267,  2.12878709],\n",
       "       ...,\n",
       "       [ 1.45348759, -0.41980384, -0.72160376, ...,  0.0103879 ,\n",
       "         1.59941309, -0.2952564 ],\n",
       "       [-0.00503608, -0.32499587, -1.27477844, ...,  1.01079509,\n",
       "         0.37585835, -0.4418095 ],\n",
       "       [ 1.26017818,  0.74884621,  0.35056416, ...,  0.33231985,\n",
       "         0.98482388, -1.19987908]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=dat_train.iloc[:,:-1]\n",
    "Y_train=dat_train.iloc[:,-1]\n",
    "\n",
    "X_test=dat_test.iloc[:,:-1]\n",
    "Y_test=dat_test.iloc[:,-1]\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.99, whiten=True)\n",
    "X_train_PCA = pca.fit_transform(X_train)\n",
    "X_train_PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_PCA[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.53867102,  0.29023548,  0.27804837, ...,  0.65310612,\n",
       "        -0.35707205, -0.00646688],\n",
       "       [ 0.73391199, -0.31705034,  1.1553738 , ..., -0.59843637,\n",
       "        -1.16381385,  0.38111103],\n",
       "       [ 0.58271613, -0.31543925,  1.07140477, ...,  1.49959578,\n",
       "         1.30442532,  1.26280335],\n",
       "       ...,\n",
       "       [-0.64984464,  0.56098929, -0.19341404, ...,  1.26425914,\n",
       "        -0.20173876,  0.75145747],\n",
       "       [-0.28863336, -1.1846612 , -0.10493293, ..., -1.16047134,\n",
       "        -0.27463411, -0.67990864],\n",
       "       [-0.34002069,  1.82417531,  2.74760097, ...,  0.53858538,\n",
       "        -2.13547731,  2.7507197 ]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_PCA = pca.transform(X_test)\n",
    "X_test_PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test_PCA[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform x\n",
    "X_train_CNN = X_train_PCA.reshape(2000, 90,1)\n",
    "X_test_CNN = X_test_PCA.reshape(500, 90,1)\n",
    "#normalize x\n",
    "X_train_CNN = X_train_CNN - np.mean(X_train_CNN, axis=0)\n",
    "X_train_CNN = X_train_CNN/np.std(X_train_CNN, axis=0)\n",
    "\n",
    "num_classes = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_16 (Conv1D)           (None, 88, 100)           400       \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 86, 100)           30100     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 86, 100)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 84, 100)           30100     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 84, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8400)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 8400)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               840100    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 22)                2222      \n",
      "=================================================================\n",
      "Total params: 902,922\n",
      "Trainable params: 902,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "import tensorflow\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv1D,Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import model_from_json\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.regularizers import l2\n",
    "\n",
    "model = Sequential()\n",
    "#first layer is Convolution Layer\n",
    "model.add(Conv1D(100, (3), input_shape=(90,1), activation='relu', kernel_regularizer=l2(0.1)))\n",
    "#Second layer is Convolution Layer\n",
    "model.add(Conv1D(100, (3), input_shape=(90,1), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "#Third layer is Convolution Layer\n",
    "model.add(Conv1D(100, (3), input_shape=(90,1), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "#Fourth layer is Flatten Layer\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "#Fifth layer is Dense Layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "#Sixth layer is Dense Layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 500 samples\n",
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.1101 - accuracy: 0.9675 - val_loss: 3.1570 - val_accuracy: 0.4860\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0814 - accuracy: 0.9745 - val_loss: 3.1082 - val_accuracy: 0.4740\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0712 - accuracy: 0.9815 - val_loss: 3.1811 - val_accuracy: 0.4640\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0686 - accuracy: 0.9850 - val_loss: 3.1081 - val_accuracy: 0.4760\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0620 - accuracy: 0.9875 - val_loss: 3.0733 - val_accuracy: 0.4840\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0448 - accuracy: 0.9910 - val_loss: 3.4816 - val_accuracy: 0.4900\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0570 - accuracy: 0.9870 - val_loss: 3.2421 - val_accuracy: 0.4740\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0579 - accuracy: 0.9865 - val_loss: 3.2634 - val_accuracy: 0.4840\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0468 - accuracy: 0.9890 - val_loss: 3.3544 - val_accuracy: 0.4740\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0449 - accuracy: 0.9855 - val_loss: 3.4673 - val_accuracy: 0.4840\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0625 - accuracy: 0.9855 - val_loss: 3.2731 - val_accuracy: 0.4700\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0503 - accuracy: 0.9870 - val_loss: 3.3928 - val_accuracy: 0.4800\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0489 - accuracy: 0.9865 - val_loss: 3.3003 - val_accuracy: 0.4640\n",
      "Epoch 14/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0295 - accuracy: 0.9945 - val_loss: 3.5696 - val_accuracy: 0.4940\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0545 - accuracy: 0.9860 - val_loss: 3.3210 - val_accuracy: 0.4720\n",
      "Epoch 16/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0334 - accuracy: 0.9940 - val_loss: 3.5513 - val_accuracy: 0.4640\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0380 - accuracy: 0.9925 - val_loss: 3.6176 - val_accuracy: 0.4780\n",
      "Epoch 18/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0423 - accuracy: 0.9890 - val_loss: 3.6863 - val_accuracy: 0.4720\n",
      "Epoch 19/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0520 - accuracy: 0.9885 - val_loss: 3.4813 - val_accuracy: 0.4560\n",
      "Epoch 20/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0332 - accuracy: 0.9910 - val_loss: 3.6033 - val_accuracy: 0.4660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1e7b846f408>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_binary = keras.utils.to_categorical(Y_train-1, num_classes)\n",
    "Y_test_binary = keras.utils.to_categorical(Y_test-1, num_classes)\n",
    "model.fit(X_train_CNN, Y_train_binary,\n",
    "          epochs=20,\n",
    "          verbose=1,\n",
    "         validation_data=(X_test_CNN, Y_test_binary))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
